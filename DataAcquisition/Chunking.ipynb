{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pathlib\n",
    "%pip install pandas\n",
    "%pip install tqdm\n",
    "%pip install python-dotenv\n",
    "%pip install langchain\n",
    "%pip install transformers\n",
    "%pip install sentence-transformers\n",
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from .env file\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gf/sz_10_bj13b1wbddz0xwrt300000gn/T/ipykernel_13406/4037576003.py:4: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('lines.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94917, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# read df from file\n",
    "\n",
    "df = pd.read_csv('lines.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I523062/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "\n",
    "hf_auth = os.environ.get('HF_AUTH')\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\",token=hf_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def token_len(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    length_function=token_len,\n",
    "    separators=['\\n\\n', '\\n', ' ', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 269\n",
      "Avg: 8849\n",
      "Max: 126133\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for celexNumber, group  in df.groupby('CELEX number'):\n",
    "    text = ' '.join([str(line) for line in group['text']])\n",
    "    texts.append(text)\n",
    "\n",
    "token_counts = [token_len(doc) for doc in texts]\n",
    "min_tokens=min(token_counts)\n",
    "avg_tokens=int(sum(token_counts) / len(token_counts))\n",
    "max_tokens=max(token_counts)\n",
    "\n",
    "print(f\"\"\"Min: {min_tokens}\n",
    "Avg: {avg_tokens}\n",
    "Max: {max_tokens}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDeepestInfoLevel(row):\n",
    "    if not pd.isna(row['number6']):\n",
    "        return 10\n",
    "    if not pd.isna(row['number5']):\n",
    "        return 9\n",
    "    if not pd.isna(row['number4']):\n",
    "        return 8\n",
    "    if not pd.isna(row['number3']):\n",
    "        return 7\n",
    "    if not pd.isna(row['number2']):\n",
    "        return 6\n",
    "    if not pd.isna(row['number1']):\n",
    "        return 5\n",
    "    if not pd.isna(row['article']):\n",
    "        return 4\n",
    "    if not pd.isna(row['section']):\n",
    "        return 3\n",
    "    return 3\n",
    "\n",
    "levelDict = {\n",
    "    3: 'section',\n",
    "    4: 'article',\n",
    "    5: 'number1',\n",
    "    6: 'number2',\n",
    "    7: 'number3',\n",
    "    8: 'number4',\n",
    "    9: 'number5',\n",
    "    10: 'number6',\n",
    "}\n",
    "\n",
    "def enumerationToText(Es):\n",
    "    text = \"\"\n",
    "    length = len(Es)\n",
    "    if length > 0:\n",
    "        text += \"Section: '\" + str(Es[0])[:20] + \"'\"\n",
    "    if length > 1:\n",
    "        if Es[1] != None and str(Es[1]) != \"\" and not pd.isna(Es[1]):\n",
    "            if isinstance(Es[1], float) and Es[1].is_integer():\n",
    "                text += \", Article \" + str(int(Es[1]))\n",
    "            else:\n",
    "                text += \", Article \" + str(Es[1])\n",
    "    if length > 2:\n",
    "        for i in range(2, length):\n",
    "            if Es[i] != None and str(Es[i]) != \"\" and not pd.isna(Es[i]):\n",
    "                if isinstance(Es[i], float) and Es[i].is_integer():\n",
    "                    text += \", \" + str(int(Es[i]))\n",
    "                else:\n",
    "                    text += \", \" + str(Es[i])\n",
    "    return text\n",
    "\n",
    "def compareEnumberations(newEs, currentEs, newSectionID, currentSectionID):\n",
    "    if newSectionID != currentSectionID:\n",
    "        return False, 3\n",
    "    minlen = min(len(newEs), len(currentEs))\n",
    "    for i in range(1, minlen):\n",
    "        if newEs[i] != currentEs[i]:\n",
    "            return False, i + 3\n",
    "    return True, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 537/537 [03:02<00:00,  2.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CELEX number</th>\n",
       "      <th>text</th>\n",
       "      <th>extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21975A1201(01)</td>\n",
       "      <td>Avis juridique important Cooperation Agreement...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21975A1201(01)</td>\n",
       "      <td>EUROPEAN ATOMIC ENERGY COMMUNITY AND THE INTER...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21975A1201(01)</td>\n",
       "      <td>Contracting Parties shall consult each other r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21975A1201(01)</td>\n",
       "      <td>with respect to items on their agenda in which...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21975A1201(01)</td>\n",
       "      <td>confidential nature of certain information and...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25792</th>\n",
       "      <td>25792</td>\n",
       "      <td>32023R2633</td>\n",
       "      <td>(1)  The Annex is subject to the pro rata obli...</td>\n",
       "      <td>Section: 'ANNEX Footnotes'; Section: 'Document'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25793</th>\n",
       "      <td>25793</td>\n",
       "      <td>42009D0913</td>\n",
       "      <td>DECISION TAKEN BY COMMON AGREEMENT BETWEEN THE...</td>\n",
       "      <td>Section: 'Document', (1); Section: 'Document'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25794</th>\n",
       "      <td>25794</td>\n",
       "      <td>42009D0913</td>\n",
       "      <td>The location of the seat of this Agency should...</td>\n",
       "      <td>Section: 'Document', Article 2; Section: 'Docu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25795</th>\n",
       "      <td>25795</td>\n",
       "      <td>42010D0349</td>\n",
       "      <td>DECISION TAKEN BY COMMON ACCORD BETWEEN THE RE...</td>\n",
       "      <td>Section: 'Document', (1); Section: 'Document',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25796</th>\n",
       "      <td>25796</td>\n",
       "      <td>42010D0349</td>\n",
       "      <td>HAVE ADOPTED THIS DECISION:\\nThe Office of the...</td>\n",
       "      <td>Section: 'Document', Article 3; Section: 'Docu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25797 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    CELEX number  \\\n",
       "0          0  21975A1201(01)   \n",
       "1          1  21975A1201(01)   \n",
       "2          2  21975A1201(01)   \n",
       "3          3  21975A1201(01)   \n",
       "4          4  21975A1201(01)   \n",
       "...      ...             ...   \n",
       "25792  25792      32023R2633   \n",
       "25793  25793      42009D0913   \n",
       "25794  25794      42009D0913   \n",
       "25795  25795      42010D0349   \n",
       "25796  25796      42010D0349   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Avis juridique important Cooperation Agreement...   \n",
       "1      EUROPEAN ATOMIC ENERGY COMMUNITY AND THE INTER...   \n",
       "2      Contracting Parties shall consult each other r...   \n",
       "3      with respect to items on their agenda in which...   \n",
       "4      confidential nature of certain information and...   \n",
       "...                                                  ...   \n",
       "25792  (1)  The Annex is subject to the pro rata obli...   \n",
       "25793  DECISION TAKEN BY COMMON AGREEMENT BETWEEN THE...   \n",
       "25794  The location of the seat of this Agency should...   \n",
       "25795  DECISION TAKEN BY COMMON ACCORD BETWEEN THE RE...   \n",
       "25796  HAVE ADOPTED THIS DECISION:\\nThe Office of the...   \n",
       "\n",
       "                                                  extras  \n",
       "0                                                   None  \n",
       "1                                                   None  \n",
       "2                                                   None  \n",
       "3                                                   None  \n",
       "4                                                   None  \n",
       "...                                                  ...  \n",
       "25792    Section: 'ANNEX Footnotes'; Section: 'Document'  \n",
       "25793      Section: 'Document', (1); Section: 'Document'  \n",
       "25794  Section: 'Document', Article 2; Section: 'Docu...  \n",
       "25795  Section: 'Document', (1); Section: 'Document',...  \n",
       "25796  Section: 'Document', Article 3; Section: 'Docu...  \n",
       "\n",
       "[25797 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "entryID = 0\n",
    "\n",
    "for celexNumber, group  in tqdm(df.groupby('CELEX number')):\n",
    "    # unstructured case:\n",
    "    if (group['sectionID'].isna().all()):\n",
    "        text = ' '.join([str(line) for line in group['text']])\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            documents.append(\n",
    "                {\n",
    "                    'id': entryID,\n",
    "                    'CELEX number': celexNumber,\n",
    "                    'text': chunk,\n",
    "                    'extras': None,\n",
    "                }\n",
    "            )\n",
    "            entryID += 1\n",
    "    else:\n",
    "        currentLevel = 2\n",
    "        currentEnumberations = []\n",
    "        currentChunk = \"\"\n",
    "        currentSectionID = 1\n",
    "\n",
    "        currentExtras = set()\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            newLevel = getDeepestInfoLevel(row)\n",
    "            newEnumberations = [row[levelDict[i]] for i in range(3,newLevel + 1)]\n",
    "            newSectionID = row['sectionID']\n",
    "            areEnumberationsSame, differringLevel = compareEnumberations(newEnumberations, currentEnumberations, newSectionID, currentSectionID)\n",
    "            currentSectionID = newSectionID\n",
    "\n",
    "            if newLevel < currentLevel:\n",
    "                if token_len(currentChunk) > 200:\n",
    "                    chunks = text_splitter.split_text(currentChunk)\n",
    "                    for chunk in chunks:\n",
    "                        documents.append({\n",
    "                            'id': entryID,\n",
    "                            'CELEX number': celexNumber,\n",
    "                            'text': chunk,\n",
    "                            'extras': \"; \".join(currentExtras),\n",
    "                        })\n",
    "                        entryID += 1\n",
    "                    currentChunk = str(row['text'])\n",
    "                    currentExtras = set()\n",
    "                else:\n",
    "                    currentChunk += '\\n' + str(row['text'])\n",
    "                currentLevel = newLevel\n",
    "                currentEnumberations = newEnumberations\n",
    "\n",
    "\n",
    "            elif newLevel == currentLevel:\n",
    "                \n",
    "                if areEnumberationsSame:\n",
    "                    currentChunk += '\\n' + str(row['text'])\n",
    "                elif differringLevel == currentLevel and differringLevel > 4:\n",
    "                    currentChunk += '\\n' + str(newEnumberations[-1]) + ' ' + str(row['text'])\n",
    "                else:\n",
    "                    if token_len(currentChunk) > 200:\n",
    "                        chunks = text_splitter.split_text(currentChunk)\n",
    "                        for chunk in chunks:\n",
    "                            documents.append({\n",
    "                                'id': entryID,\n",
    "                                'CELEX number': celexNumber,\n",
    "                                'text': chunk,\n",
    "                                'extras': \"; \".join(currentExtras),\n",
    "                            })\n",
    "                            entryID += 1\n",
    "                        currentChunk = str(row['text'])\n",
    "                        currentExtras = set()\n",
    "                    else:\n",
    "                        currentChunk += '\\n' + str(row['text'])\n",
    "                    currentLevel = newLevel\n",
    "                    currentEnumberations = newEnumberations\n",
    "\n",
    "            else:\n",
    "                if token_len(currentChunk) > 200:\n",
    "                    chunks = text_splitter.split_text(currentChunk)\n",
    "                    for chunk in chunks:\n",
    "                        documents.append({\n",
    "                            'id': entryID,\n",
    "                            'CELEX number': celexNumber,\n",
    "                            'text': chunk,\n",
    "                            'extras': \"; \".join(currentExtras),\n",
    "                        })\n",
    "                        entryID += 1\n",
    "                    currentChunk = str(row['text'])\n",
    "                    currentExtras = set()\n",
    "                else:\n",
    "                    currentChunk += '\\n' + str(row['text'])\n",
    "                currentEnumberations = newEnumberations\n",
    "                currentLevel = newLevel\n",
    "            \n",
    "            currentExtras.add(enumerationToText(currentEnumberations))\n",
    "\n",
    "        \n",
    "        chunks = text_splitter.split_text(currentChunk)\n",
    "        for chunk in chunks:\n",
    "            documents.append({\n",
    "                'id': entryID,\n",
    "                'CELEX number': celexNumber,\n",
    "                'text': chunk,\n",
    "                'extras': \"; \".join(currentExtras),\n",
    "            })\n",
    "            entryID += 1\n",
    "        \n",
    "documents_df = pd.DataFrame(documents)\n",
    "documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv file\n",
    "\n",
    "from pathlib import Path \n",
    "filepath = Path('chunks.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True) \n",
    "documents_df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files processed:537\n"
     ]
    }
   ],
   "source": [
    "print('files processed:' + str(documents_df['CELEX number'].nunique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
